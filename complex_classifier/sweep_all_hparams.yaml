program: train_pole_classifier.py
method: bayes
entity: "ml-tpp"
project: "pole_classifier"
name: "sweep_all_hparams"
description: "sweep over all relevant training and network hyperparameters"
metric:
  name: test_acc_averaged
  goal: maximize
parameters:
  hidden_dim_classifier:
    distribution: int_uniform
    min: 1
    max: 512   # may be too large; if larger nets don't help then prefer small nets
  architecture_classifier:
    distribution: categorical  # if deep nets don't help then prefer shallow nets
    values: ["FC1", "FC2", "FC3", "FC4", "FC5", "FC6"]
  batch_size_classifier:
    distribution: int_uniform # maybe instead categorical with 1,2,4,..,512?
    min: 1
    max: 512  # maybe too large? usually 32 is good
  learning_rate_classifier:
    distribution: log_uniform
    min: -13.815510557964275 #2.302585092994046 * (-6.0) # may be too small
    max: -2.302585092994046  #2.302585092994046 * (-1.0)
  optimizer_classifier:
    distribution: categorical
    values: ["Adam", "AdamW", "Adagrad", "Adadelta", "RMSprop", "SGD"]
  weight_decay_classifier:
    distribution: log_uniform
    min: -20.723265836946414 #2.302585092994046 * (-9.0) # too small?
    max: -2.302585092994046  #2.302585092994046 * (-1.0)
  drop_prob_classifier:
    distribution: uniform
    min: 0.0
    max: 1.0

